{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "year = 2010\n",
    "DPATH = '../07_HINTS_code-main/fanxing/'\n",
    "with open(f'{DPATH}/individual_data/graph_' + str(year - 5) + '_nf.pkl', 'rb') as f:\n",
    "    graph_1 = pkl.load(f)\n",
    "    # adj_ = [normalize(adj_)for adj_ in graph_1['adj']]  # adj: list(sp.csr_matrix)\n",
    "    adj = graph_1['adj']\n",
    "    # print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (750602, 750602) (750602, 750602) (750602, 750602) (750602, 750602) (750602, 750602)\n",
      "(750602, 4)\n"
     ]
    }
   ],
   "source": [
    "print(len(adj), adj[0].shape, adj[1].shape, adj[2].shape, adj[3].shape, adj[4].shape, )\n",
    "print(graph_1['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058244 1058244\n",
      "torch.Size([2, 1058244])\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import torch\n",
    "adj_coo = adj[0].tocoo()\n",
    "row, col = adj_coo.row, adj_coo.col\n",
    "print(len(row), len(col))\n",
    "edge_index = torch.zeros((2, len(row))).to(torch.long)\n",
    "edge_index[0] = torch.from_numpy(row)\n",
    "edge_index[1] = torch.from_numpy(col)\n",
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([750602, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
    "periods = 1; inc = 4; outc=2\n",
    "model = A3TGCN(in_channels=inc, out_channels=outc, periods=periods).to('cpu')\n",
    "feat = torch.from_numpy(graph_1['feature']).reshape((-1, 4, 1)).to(torch.float)\n",
    "a = model(feat, edge_index) # [750602, 2]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn.attention import ASTGCN\n",
    "bs=1; periods = 1; inc = 4; outc=2\n",
    "node_num = 10\n",
    "model = ASTGCN(nb_block=2, in_channels=inc, K=2, nb_chev_filter=2, nb_time_filter=2, time_strides=1,\\\n",
    "    num_for_predict=outc, len_input=periods, num_of_vertices=node_num).to('cuda')\n",
    "# feat = torch.from_numpy(graph_1['feature']).reshape((-1, 4, 1)).to(torch.float)\n",
    "feat = torch.rand(bs, node_num, 4, 1).to('cuda')\n",
    "edge_index = (torch.rand(2, 5)*node_num).to(torch.long).to('cuda')\n",
    "a = model(feat, edge_index) # [750602, 2]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 750602, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn.attention import MSTGCN\n",
    "bs=1; periods = 1; inc = 4; outc=2\n",
    "node_num = 10\n",
    "model = MSTGCN(nb_block=2, in_channels=inc, K=2, nb_chev_filter=2, nb_time_filter=2, time_strides=1,\\\n",
    "    num_for_predict=outc, len_input=periods).to('cuda')\n",
    "feat = torch.from_numpy(graph_1['feature']).reshape((bs, -1, 4, 1)).to(torch.float)\n",
    "# feat = torch.rand(bs, node_num, 4, 1).to('cuda')\n",
    "# edge_index = (torch.rand(2, 5)*node_num).to(torch.long).to('cuda')\n",
    "a = model(feat.to('cuda'), edge_index.to('cuda')) # [750602, 2]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:67] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2253613449616 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-13c9514ccd37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mperiods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0moutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mASTGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_chev_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_time_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_strides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mnum_for_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperiods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# feat = torch.rand(bs, node_num, 4, 1).to('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/expc/lib/python3.6/site-packages/torch_geometric_temporal/nn/attention/astgcn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, num_for_predict, len_input, num_of_vertices, normalization, bias)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mlen_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                     \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 )\n\u001b[1;32m    549\u001b[0m             ]\n",
      "\u001b[0;32m~/miniconda3/envs/expc/lib/python3.6/site-packages/torch_geometric_temporal/nn/attention/astgcn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, num_of_vertices, num_of_timesteps, normalization, bias)\u001b[0m\n\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m         self._spatial_attention = SpatialAttention(\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         )\n\u001b[1;32m    383\u001b[0m         self._chebconv_attention = ChebConvAttention(\n",
      "\u001b[0;32m~/miniconda3/envs/expc/lib/python3.6/site-packages/torch_geometric_temporal/nn/attention/astgcn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, num_of_vertices, num_of_timesteps)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_W2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for example (1, 12)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_W3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for example (1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for example (1,307, 307)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Vs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_vertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for example (307, 307)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:67] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2253613449616 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "bs=1; periods = 1; inc = 4; outc=2\n",
    "node_num = len(graph_1['feature'])\n",
    "model = ASTGCN(nb_block=1, in_channels=inc, K=1, nb_chev_filter=1, nb_time_filter=1, time_strides=1,\\\n",
    "    num_for_predict=outc, len_input=periods, num_of_vertices=node_num).to('cuda')\n",
    "feat = torch.from_numpy(graph_1['feature']).reshape((bs, -1, 4, 1)).to(torch.float).to('cuda')\n",
    "# feat = torch.rand(bs, node_num, 4, 1).to('cuda')\n",
    "# edge_index = (torch.rand(2, 5)*node_num).to(torch.long).to('cuda')\n",
    "a = model(feat, edge_index.to('cuda')) # [750602, 2]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[rank].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = TGCN(in_channels=inc, out_channels=outc)\n",
    "feat = torch.from_numpy(graph_1['feature']).reshape((-1, 4, 1)).to(torch.float)\n",
    "a = model(feat, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,) (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "# import torch.nn as nn\n",
    "# loss_f = nn.MSELoss()\n",
    "rank = pkl.load(open(f'../07_HINTS_code-main/aminer/select_index_train.pkl', 'rb')) # [3000]\n",
    "labels = pkl.load(open(f'{DPATH}/data/cumulative_log_labels_new.pkl', 'rb'))['P' + str(year) + '_label'].iloc[rank, 1:6].values\n",
    "print(rank.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a[rank]\n",
    "out.shape\n",
    "\n",
    "# print(out.shape, lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 189098, 100)\n"
     ]
    }
   ],
   "source": [
    "index = pkl.load(open(f'{DPATH}/individual_data/index_' + str(year) + '.pkl', 'rb')) \n",
    "index_table_P1P = index[0]\n",
    "print(index[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750602 750602\n"
     ]
    }
   ],
   "source": [
    "id_item, item_id = graph_1['id_item'], graph_1['item_id']\n",
    "print(len(id_item), len(item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'53e99abeb7602d970233cdda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9e4564f1e838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'53e99abeb7602d970233cdda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '53e99abeb7602d970233cdda'"
     ]
    }
   ],
   "source": [
    "item_id['53e99abeb7602d970233cdda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 771/750602 [00:14<3:58:27, 52.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771 53e9b746b7602d97042e3386\n",
      "                               P  citation_2011  citation_2012  citation_2013  \\\n",
      "161483  53e9b746b7602d97042e3386            0.0            0.0            0.0   \n",
      "\n",
      "        citation_2014  citation_2015  citation_2016  citation_2017  \\\n",
      "161483            0.0            0.0            0.0            0.0   \n",
      "\n",
      "        citation_2018  citation_2019  citation_2020  citation_2021  \n",
      "161483            0.0            0.0            0.0            0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import trange\n",
    "# for i in trange(len(id_item)):\n",
    "#     item = id_item[i]\n",
    "#     df3 = labels[labels['P']==item]\n",
    "#     if len(df3)>0:\n",
    "#         print(i, item)\n",
    "#         print(df3)\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3000, 100)\n"
     ]
    }
   ],
   "source": [
    "index_table_P1P = index[0][:,rank,:]\n",
    "print(index_table_P1P.shape)\n",
    "# batch_size = 2\n",
    "# index_P = [index[i*batch_size:(i+1)*batch_size,:] for index in index_table_P1P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  7,  9, 11, 17, 23, 24, 25, 28, 31])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 100, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = a[index_table_P1P[0]]\n",
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztl/miniconda3/envs/expc/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in power\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600391, 4) (697400, 4) (789677, 4) (867984, 4) (977953, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def lable_normorlization(labels):\n",
    "    maximum = labels.max()\n",
    "    minimum = labels.min()\n",
    "    new_value = (labels-minimum)/(maximum-minimum)\n",
    "    return new_value,maximum,minimum\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1)) # [n, 1]\n",
    "    r_inv = np.power(rowsum, -1).flatten() #[n]\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv) # [n, n]\n",
    "    mx = r_mat_inv.dot(mx) # [n, n]\n",
    "    return mx\n",
    "\n",
    "\n",
    "def adj2edge_index(adj):\n",
    "    adj_coo = adj.tocoo()\n",
    "    row, col = adj_coo.row, adj_coo.col\n",
    "    edge_index = torch.zeros((2, len(row))).to(torch.long)\n",
    "    edge_index[0] = torch.from_numpy(row)\n",
    "    edge_index[1] = torch.from_numpy(col)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "# def load_data_dblpV13(year,flag):\n",
    "def load_data_aminer(year,flag):\n",
    "    # DPATH = '../07_HINTS_code-main/fanxing'\n",
    "    DPATH = '../07_HINTS_code-main/aminer'\n",
    "    with open(f'{DPATH}/individual_data/graph_' + str(year - 5) + '_nf.pkl', 'rb') as f:\n",
    "        graph_1 = pkl.load(f)\n",
    "        adj_ = [normalize(adj_)for adj_ in graph_1['adj']] # adj: list(sp.csr_matrix), 5个类型\n",
    "        adj_1 = [adj2edge_index(adj) for adj in adj_]\n",
    "        feature_1 = graph_1['feature'] # np.array, [n, 4]\n",
    "\n",
    "    with open(f'{DPATH}/individual_data/graph_' + str(year - 4) + '_nf.pkl', 'rb') as f:\n",
    "        graph_2 = pkl.load(f)\n",
    "        adj_ = [normalize(adj_)for adj_ in graph_2['adj']]\n",
    "        adj_2 = [adj2edge_index(adj) for adj in adj_]\n",
    "        feature_2 = graph_2['feature']\n",
    "    \n",
    "    with open(f'{DPATH}/individual_data/graph_' + str(year - 3) + '_nf.pkl', 'rb') as f:\n",
    "        graph_3 = pkl.load(f)\n",
    "        adj_ = [normalize(adj_)for adj_ in graph_3['adj']]\n",
    "        adj_3 = [adj2edge_index(adj) for adj in adj_]\n",
    "        feature_3 = graph_3['feature']\n",
    "\n",
    "    with open(f'{DPATH}/individual_data/graph_' + str(year - 2) + '_nf.pkl', 'rb') as f:\n",
    "        graph_4 = pkl.load(f)\n",
    "        adj_ = [normalize(adj_)for adj_ in graph_4['adj']]\n",
    "        adj_4 = [adj2edge_index(adj) for adj in adj_]\n",
    "        feature_4 = graph_4['feature']\n",
    "\n",
    "    with open(f'{DPATH}/individual_data/graph_' + str(year - 1) + '_nf.pkl', 'rb') as f:\n",
    "        graph_5 = pkl.load(f)\n",
    "        adj_ = [normalize(adj_)for adj_ in graph_5['adj']]\n",
    "        adj_5 = [adj2edge_index(adj) for adj in adj_]\n",
    "        feature_5 = graph_5['feature']\n",
    "    \n",
    "    edge_list = []\n",
    "    for i in range(len(adj_1)):\n",
    "        # tt = torch.stack([adj_1[0], adj_2[1], adj_3,adj_4,adj_5], dim=)\n",
    "        edge_list.append( [adj_1[i], adj_2[i], adj_3[i], adj_4[i], adj_5[i] ] )\n",
    "\n",
    "    print(feature_1.shape, feature_2.shape, feature_3.shape, feature_4.shape, feature_5.shape, )\n",
    "    ls = (600391, 4)\n",
    "    # for i in range(2):\n",
    "    #     ls[i] = min(feature_1.shape[i], feature_2.shape[i], feature_3.shape[i], feature_4.shape[i], feature_5.shape[i])\n",
    "    # ee = min(feature_1.shape[1], feature_2.shape[0], feature_3.shape[0], feature_4.shape[0], feature_5.shape[0])\n",
    "    feature_np = np.stack([feature_1[:ls[0], :ls[1]], feature_2[:ls[0], :ls[1]], feature_3[:ls[0], :ls[1]],\\\n",
    "        feature_4[:ls[0], :ls[1]], feature_5[:ls[0], :ls[1]] ], axis=-1) # [n, 4, 5]\n",
    "    feature = torch.from_numpy(feature_np).to(torch.float)\n",
    "\n",
    "    if flag == \"train\":\n",
    "        with open(f'{DPATH}/select_index_train.pkl','rb') as f:\n",
    "            rank = pkl.load(f) # rank : shape=(3000,), [   2    7    9 ... 9009 9045 9062]\n",
    "\n",
    "    elif flag == \"test\":\n",
    "        with open(F'{DPATH}/select_index_test.pkl','rb') as f:\n",
    "            rank = pkl.load(f)\n",
    "    \n",
    "    with open(f'{DPATH}/cumulative_log_labels_new.pkl','rb') as f: # len=13, 2005-2017的引用情况\n",
    "        # 13个csv，每一列是year-2018的引用量\n",
    "        labels = pkl.load(f)['P' + str(year) + '_label'].iloc[rank, 1:6].values # shape=(3000, 5)\n",
    "    \n",
    "    labels, label_max, label_min = lable_normorlization(labels)\n",
    "\n",
    "    return edge_list, feature, labels, label_max, label_min\n",
    "\n",
    "edge_list, feature, labels, label_max, label_min = load_data_aminer(2010, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([], size=(2, 0), dtype=torch.int64),\n",
       " tensor([], size=(2, 0), dtype=torch.int64),\n",
       " tensor([], size=(2, 0), dtype=torch.int64),\n",
       " tensor([], size=(2, 0), dtype=torch.int64),\n",
       " tensor([], size=(2, 0), dtype=torch.int64)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16645643c17dc88eeffdbbe591c8bf09dd1623e56489d011928baad9e6835b88"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 ('expc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
